#!/usr/bin/env python3
"""
TSLAè‚¡ç¥¨åˆ†æè„šæœ¬ - 2025å¹´èµ°åŠ¿åˆ†æåŠæœªæ¥è¶‹åŠ¿é¢„æµ‹
ä½¿ç”¨qlibå¤šä¸ªæ¨¡å‹è¿›è¡Œé‡åŒ–åˆ†æå’Œé¢„æµ‹ï¼ŒåŠ¨æ€æƒé‡åˆ†é…
"""
import os
import sys
import warnings
warnings.filterwarnings('ignore')

print("=== TSLAè‚¡ç¥¨åˆ†æ - åŸºäºQlibå¤šæ¨¡å‹çš„æ™ºèƒ½é‡åŒ–åˆ†æ ===")

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = "/workspace/output"
plots_dir = "/workspace/output/plots"
os.makedirs(output_dir, exist_ok=True)
os.makedirs(plots_dir, exist_ok=True)

try:
    # å¯¼å…¥å¿…è¦çš„åº“
    import pandas as pd
    import numpy as np
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import seaborn as sns
    from datetime import datetime, timedelta
    import yfinance as yf
    
    # æ™ºèƒ½å¯¼å…¥qlibæ¨¡å—
    qlib_models = {}
    qlib_available = False
    
    try:
        import qlib
        from qlib.constant import REG_US
        qlib_available = True
        print("âœ“ qlibæ¡†æ¶å¯¼å…¥æˆåŠŸ")
        
        # å…ˆå°è¯•å®‰è£…å¯èƒ½ç¼ºå¤±çš„ä¾èµ–
        missing_deps = []
        try:
            import torch
            print("âœ“ PyTorchå·²å®‰è£…")
        except ImportError:
            missing_deps.append("torch")
            
        try:
            import xgboost
            print("âœ“ XGBoostå·²å®‰è£…")
        except ImportError:
            missing_deps.append("xgboost")
            
        try:
            import catboost
            print("âœ“ CatBoostå·²å®‰è£…") 
        except ImportError:
            missing_deps.append("catboost")
            
        try:
            import pytorch_tabnet
            print("âœ“ PyTorch-TabNetå·²å®‰è£…")
        except ImportError:
            missing_deps.append("pytorch-tabnet")
        
        if missing_deps:
            print(f"âš  ç¼ºå¤±ä¾èµ–: {', '.join(missing_deps)}")
            print("æ­£åœ¨å°è¯•å®‰è£…ç¼ºå¤±çš„ä¾èµ–...")
            try:
                import subprocess
                import sys
                for dep in missing_deps:
                    if dep == "torch":
                        subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "--index-url", "https://download.pytorch.org/whl/cpu", "--quiet"])
                    else:
                        subprocess.check_call([sys.executable, "-m", "pip", "install", dep, "--quiet"])
                print("âœ“ ä¾èµ–å®‰è£…å®Œæˆ")
            except Exception as e:
                print(f"âš  ä¾èµ–å®‰è£…å¤±è´¥: {e}")
        
        # å°è¯•å¯¼å…¥å„ç§æ¨¡å‹ï¼Œä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
        model_imports = [
            # åŸºç¡€æ¨¡å‹ - ä½¿ç”¨ç¡®è®¤å­˜åœ¨çš„è·¯å¾„
            ('LGBModel', 'qlib.contrib.model.gbdt', 'LGBModel'),
            ('LinearModel', 'qlib.contrib.model.linear', 'LinearModel'),
            ('XGBModel', 'qlib.contrib.model.xgboost', 'XGBModel'),
            
            # æ·±åº¦å­¦ä¹ æ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„ç±»å
            ('GRU', 'qlib.contrib.model.pytorch_gru', 'GRU'),
            ('LSTM', 'qlib.contrib.model.pytorch_lstm', 'LSTM'),
            
            # æ›¿æ¢æœ‰é—®é¢˜çš„qlibæ¨¡å‹ä¸ºç¨³å®šçš„ç¬¬ä¸‰æ–¹æ¨¡å‹
            ('MLPModel', 'sklearn.neural_network', 'MLPRegressor', 'sklearn_direct'),
            ('AdaBoostModel', 'sklearn.ensemble', 'AdaBoostRegressor', 'sklearn_direct'),
            
            # ç¬¬ä¸‰æ–¹æ¨¡å‹ - ç¡®ä¿æ­£ç¡®å¤„ç†
            ('RidgeModel', 'sklearn.linear_model', 'Ridge', 'sklearn_direct'),
            ('CatBoostModel', 'catboost', 'CatBoostRegressor', 'sklearn_direct'),
            ('TabNetModel', 'pytorch_tabnet.tab_model', 'TabNetRegressor', 'tabnet_special'),
            ('SVMModel', 'sklearn.svm', 'SVR', 'sklearn_direct'),
            ('RandomForestModel', 'sklearn.ensemble', 'RandomForestRegressor', 'sklearn_direct'),
            # æ·»åŠ æ›´å¤šsklearnæ¨¡å‹ä½œä¸ºå¤‡é€‰
            ('GradientBoostingModel', 'sklearn.ensemble', 'GradientBoostingRegressor', 'sklearn_direct'),
            ('ExtraTreesModel', 'sklearn.ensemble', 'ExtraTreesRegressor', 'sklearn_direct'),
            ('BaggingModel', 'sklearn.ensemble', 'BaggingRegressor', 'sklearn_direct'),
        ]
        
        # å¯¼å…¥æ¨¡å‹ï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹å¼
        for model_info in model_imports:
            if len(model_info) == 3:
                model_display_name, module_path, class_name = model_info
                wrapper_type = None
            else:
                model_display_name, module_path, class_name, wrapper_type = model_info
                
            try:
                if wrapper_type == 'sklearn_direct':
                    # ç›´æ¥ä½¿ç”¨ç¬¬ä¸‰æ–¹åº“ï¼Œåœ¨MLåˆ†æä¸­åŒ…è£…
                    exec(f"from {module_path} import {class_name}")
                    qlib_models[model_display_name] = eval(class_name)
                    print(f"âœ“ {model_display_name} (ç¬¬ä¸‰æ–¹) å¯¼å…¥æˆåŠŸ")
                else:
                    # æ ‡å‡†qlibæ¨¡å‹å¯¼å…¥
                    exec(f"from {module_path} import {class_name}")
                    # å°è¯•å®ä¾‹åŒ–æµ‹è¯•
                    test_model = eval(class_name)()
                    if hasattr(test_model, 'fit') and hasattr(test_model, 'predict'):
                        qlib_models[model_display_name] = eval(class_name)
                        print(f"âœ“ {model_display_name} å¯¼å…¥æˆåŠŸ")
                    else:
                        print(f"âš  {model_display_name} æ¥å£ä¸å®Œæ•´")
            except Exception as e:
                print(f"âš  {model_display_name} å¯¼å…¥å¤±è´¥: {str(e)[:80]}")
        
        print(f"âœ“ æ€»å…±æˆåŠŸå¯¼å…¥ {len(qlib_models)} ä¸ªqlibæ¨¡å‹")
        
        # è¯¦ç»†æ¨¡å‹å¯¼å…¥ç»Ÿè®¡
        if qlib_models:
            print("=== æˆåŠŸå¯¼å…¥çš„æ¨¡å‹åˆ—è¡¨ ===")
            for i, (name, model_class) in enumerate(qlib_models.items(), 1):
                model_type = "ç¬¬ä¸‰æ–¹" if name in ['RidgeModel', 'CatBoostModel', 'TabNetModel', 'SVMModel', 'RandomForestModel'] else "qlibåŸç”Ÿ"
                print(f"{i}. {name} ({model_type})")
        else:
            print("âš  æ²¡æœ‰æˆåŠŸå¯¼å…¥ä»»ä½•æ¨¡å‹")
        print("=" * 50)
        
        # å°è¯•åˆå§‹åŒ–qlib (ä½¿ç”¨æ›´é€šç”¨çš„è·¯å¾„)
        try:
            qlib.init(provider_uri='~/.qlib/qlib_data/us_data', region=REG_US)
            print("âœ“ qlibæ•°æ®åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            try:
                # å°è¯•å…¶ä»–è·¯å¾„
                qlib.init(provider_uri='/tmp/qlib_data', region=REG_US)
                print("âœ“ qlibæ•°æ®åˆå§‹åŒ–æˆåŠŸ (å¤‡ç”¨è·¯å¾„)")
            except Exception as e2:
                print(f"âš  qlibæ•°æ®åˆå§‹åŒ–å¤±è´¥: {e2}")
            
    except ImportError as e:
        print(f"âš  qlibæ¡†æ¶å¯¼å…¥å¤±è´¥: {e}")
        qlib_available = False
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    
    print("âœ“ åŸºç¡€ç¯å¢ƒé…ç½®å®Œæˆ")
    
    # è·å–TSLAè‚¡ç¥¨æ•°æ®
    print("æ­£åœ¨è·å–TSLAè‚¡ç¥¨æ•°æ®...")
    
    # è·å–æ›´é•¿æ—¶é—´çš„æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒ (2å¹´æ•°æ®)
    end_date = datetime.now()
    start_date = datetime(2023, 1, 1)  # æ‰©å±•åˆ°2023å¹´å¼€å§‹
    
    # ç›´æ¥ä½¿ç”¨yf.download()è·å–æ•°æ®
    tsla_data = yf.download("TSLA", start=start_date, end=end_date, interval="1d")
    
    # å¤„ç†å¤šçº§åˆ—ç´¢å¼•é—®é¢˜
    if isinstance(tsla_data.columns, pd.MultiIndex):
        tsla_data.columns = tsla_data.columns.droplevel(1)
    
    # è·å–2025å¹´çš„æ•°æ®
    tsla_2025 = tsla_data[tsla_data.index >= '2025-01-01']
    
    print(f"âœ“ è·å–åˆ°TSLAæ•°æ®: {len(tsla_data)} ä¸ªäº¤æ˜“æ—¥")
    print(f"âœ“ 2025å¹´æ•°æ®: {len(tsla_2025)} ä¸ªäº¤æ˜“æ—¥")
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’ŒAlphaå› å­
    def calculate_features(data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’Œé‡åŒ–å› å­"""
        df = data.copy()
        
        # ç¡®ä¿æ•°æ®åˆ—åæ­£ç¡®
        if 'Adj Close' in df.columns:
            df['Close'] = df['Adj Close']
        
        # åŸºç¡€æŠ€æœ¯æŒ‡æ ‡
        df['MA5'] = df['Close'].rolling(window=5).mean()
        df['MA10'] = df['Close'].rolling(window=10).mean()
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['MA50'] = df['Close'].rolling(window=50).mean()
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['Close'].ewm(span=12).mean()
        exp2 = df['Close'].ewm(span=26).mean()
        df['MACD'] = exp1 - exp2
        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
        
        # å¸ƒæ—å¸¦
        df['BB_Middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
        df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
        
        # ä»·æ ¼ç›¸å…³ç‰¹å¾
        df['Returns'] = df['Close'].pct_change()
        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))
        df['Volatility'] = df['Returns'].rolling(window=20).std() * np.sqrt(252)
        
        # é‡ä»·å…³ç³»
        df['Price_Volume'] = df['Close'] * df['Volume']
        df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']
        
        # åŠ¨é‡æŒ‡æ ‡
        df['ROC_5'] = (df['Close'] / df['Close'].shift(5) - 1) * 100
        df['ROC_10'] = (df['Close'] / df['Close'].shift(10) - 1) * 100
        df['ROC_20'] = (df['Close'] / df['Close'].shift(20) - 1) * 100
        
        # å¸ƒæ—å¸¦ä½ç½®
        df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
        
        # ç›¸å¯¹ä»·æ ¼ä½ç½® (è¿‡å»20å¤©)
        df['Price_Position'] = (df['Close'] - df['Close'].rolling(20).min()) / (df['Close'].rolling(20).max() - df['Close'].rolling(20).min())
        
        # å¨å»‰å§†æ–¯%R
        df['Williams_R'] = ((df['Close'].rolling(14).max() - df['Close']) / 
                           (df['Close'].rolling(14).max() - df['Close'].rolling(14).min())) * -100
        
        # KDJæŒ‡æ ‡
        low_14 = df['Low'].rolling(14).min()
        high_14 = df['High'].rolling(14).max()
        rsv = (df['Close'] - low_14) / (high_14 - low_14) * 100
        df['K'] = rsv.ewm(com=2).mean()
        df['D'] = df['K'].ewm(com=2).mean()
        df['J'] = 3 * df['K'] - 2 * df['D']
        
        return df
    
    # å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®
    def prepare_ml_data(data, prediction_days=5):
        """å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ® - ä½¿ç”¨qlibæ ¼å¼"""
        df = data.copy()
        
        # ç‰¹å¾åˆ— (å»é™¤NaNå€¼å¤šçš„åˆ—)
        feature_cols = [
            'RSI', 'MACD', 'MACD_Histogram', 
            'Returns', 'Volatility', 'Volume_Ratio',
            'ROC_5', 'ROC_10', 'ROC_20', 
            'BB_Position', 'Price_Position'
        ]
        
        # ç›®æ ‡å˜é‡ï¼šæœªæ¥Nå¤©æ”¶ç›Šç‡
        df['Target'] = df['Close'].shift(-prediction_days) / df['Close'] - 1
        
        # ç§»é™¤NaNå€¼
        df_clean = df[feature_cols + ['Target']].dropna()
        
        if len(df_clean) < 50:
            return None, None, None
        
        # å‡†å¤‡qlibæ ¼å¼çš„æ•°æ®
        try:
            from qlib.data.dataset.handler import DataHandlerLP
            from qlib.data.dataset import DatasetH
            import pandas as pd
            
            # é‡æ–°ç´¢å¼•æ•°æ®ï¼Œç¡®ä¿æœ‰æ—¶é—´ç´¢å¼•
            df_clean = df_clean.copy()
            if not isinstance(df_clean.index, pd.DatetimeIndex):
                df_clean.index = pd.to_datetime(df_clean.index)
            
            # æ·»åŠ symbolåˆ—ï¼ˆqlibéœ€è¦ï¼‰
            df_clean['symbol'] = 'TSLA'
            df_clean = df_clean.set_index(['symbol'], append=True)
            df_clean = df_clean.reorder_levels([1, 0])  # symbol, datetime
            
            # åˆ›å»ºqlibæ•°æ®é›†
            # è¿™æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›numpyæ ¼å¼ä½†ç¡®ä¿ä¸qlibå…¼å®¹
            X_df = df_clean[feature_cols]
            y_series = df_clean['Target']
            
            return X_df, y_series, feature_cols
            
        except ImportError:
            # å¦‚æœqlibæ•°æ®å¤„ç†ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼
            X_df = df_clean[feature_cols]
            y_series = df_clean['Target']
            return X_df, y_series, feature_cols
    
    # å¤šç§åˆ†ææ¨¡å‹ï¼ˆç»“åˆqlibå’ŒæŠ€æœ¯åˆ†æï¼‰
    def multi_model_analysis(data):
        """ä½¿ç”¨å¤šç§åˆ†ææ–¹æ³•è¿›è¡Œé¢„æµ‹"""
        latest = data.iloc[-1]
        predictions = {}
        
        # æ¨¡å‹1: æŠ€æœ¯åˆ†æè¶‹åŠ¿è·Ÿè¸ªæ¨¡å‹
        trend_score = 0
        trend_signals = []
        
        if latest['Close'] > latest['MA5'] > latest['MA10'] > latest['MA20']:
            trend_score = 3
            trend_signals.append("å¼ºåŠ¿ä¸Šå‡è¶‹åŠ¿")
        elif latest['Close'] > latest['MA10'] > latest['MA20']:
            trend_score = 2
            trend_signals.append("æ¸©å’Œä¸Šå‡è¶‹åŠ¿")
        elif latest['Close'] > latest['MA20']:
            trend_score = 1
            trend_signals.append("è½»å¾®ä¸Šå‡è¶‹åŠ¿")
        elif latest['Close'] < latest['MA5'] < latest['MA10'] < latest['MA20']:
            trend_score = -3
            trend_signals.append("å¼ºåŠ¿ä¸‹é™è¶‹åŠ¿")
        elif latest['Close'] < latest['MA10'] < latest['MA20']:
            trend_score = -2
            trend_signals.append("æ¸©å’Œä¸‹é™è¶‹åŠ¿")
        elif latest['Close'] < latest['MA20']:
            trend_score = -1
            trend_signals.append("è½»å¾®ä¸‹é™è¶‹åŠ¿")
        else:
            trend_score = 0
            trend_signals.append("æ¨ªç›˜éœ‡è¡")
            
        predictions['TechnicalTrend'] = {
            'score': trend_score,
            'signals': trend_signals,
            'prediction_pct': trend_score * 0.015,
            'confidence': min(abs(trend_score) * 25 + 10, 90),
            'model_type': 'technical'
        }
        
        # æ¨¡å‹2: åŠ¨é‡æŒ¯è¡å™¨æ¨¡å‹
        momentum_score = 0
        momentum_signals = []
        
        if latest['RSI'] < 30 and latest['ROC_5'] < -5:
            momentum_score = 2
            momentum_signals.append("RSIè¶…å–+åŠ¨é‡ä¸‹è·Œ")
        elif latest['RSI'] > 70 and latest['ROC_5'] > 5:
            momentum_score = -2
            momentum_signals.append("RSIè¶…ä¹°+åŠ¨é‡ä¸Šæ¶¨")
        elif latest['ROC_5'] > 3:
            momentum_score = 1
            momentum_signals.append("çŸ­æœŸåŠ¨é‡å‘ä¸Š")
        elif latest['ROC_5'] < -3:
            momentum_score = -1
            momentum_signals.append("çŸ­æœŸåŠ¨é‡å‘ä¸‹")
        else:
            momentum_signals.append("åŠ¨é‡ä¸­æ€§")
            
        predictions['MomentumOscillator'] = {
            'score': momentum_score,
            'signals': momentum_signals,
            'prediction_pct': momentum_score * 0.012,
            'confidence': min(abs(momentum_score) * 30 + 15, 85),
            'model_type': 'technical'
        }
        
        # æ¨¡å‹3: å‡å€¼å›å½’æ¨¡å‹
        reversion_score = 0
        reversion_signals = []
        
        if latest['BB_Position'] < 0.1 and latest['Williams_R'] < -80:
            reversion_score = 2
            reversion_signals.append("å¸ƒæ—å¸¦ä¸‹è½¨+å¨å»‰è¶…å–")
        elif latest['BB_Position'] > 0.9 and latest['Williams_R'] > -20:
            reversion_score = -2
            reversion_signals.append("å¸ƒæ—å¸¦ä¸Šè½¨+å¨å»‰è¶…ä¹°")
        elif latest['BB_Position'] < 0.3:
            reversion_score = 1
            reversion_signals.append("æ¥è¿‘å¸ƒæ—å¸¦ä¸‹è½¨")
        elif latest['BB_Position'] > 0.7:
            reversion_score = -1
            reversion_signals.append("æ¥è¿‘å¸ƒæ—å¸¦ä¸Šè½¨")
        else:
            reversion_signals.append("å¸ƒæ—å¸¦ä¸­æ€§åŒºåŸŸ")
            
        predictions['MeanReversion'] = {
            'score': reversion_score,
            'signals': reversion_signals,
            'prediction_pct': reversion_score * 0.010,
            'confidence': min(abs(reversion_score) * 28 + 12, 88),
            'model_type': 'technical'
        }
        
        # æ¨¡å‹4: MACD+KDJç»¼åˆæ¨¡å‹
        macd_kdj_score = 0
        macd_kdj_signals = []
        
        if (latest['MACD'] > latest['MACD_Signal'] and latest['MACD_Histogram'] > 0 and 
            latest['K'] > latest['D'] and latest['J'] > 80):
            macd_kdj_score = 2
            macd_kdj_signals.append("MACDé‡‘å‰+KDJè¶…ä¹°")
        elif (latest['MACD'] < latest['MACD_Signal'] and latest['MACD_Histogram'] < 0 and 
              latest['K'] < latest['D'] and latest['J'] < 20):
            macd_kdj_score = -2
            macd_kdj_signals.append("MACDæ­»å‰+KDJè¶…å–")
        elif latest['MACD'] > latest['MACD_Signal']:
            macd_kdj_score = 1
            macd_kdj_signals.append("MACDé‡‘å‰ä¿¡å·")
        elif latest['MACD'] < latest['MACD_Signal']:
            macd_kdj_score = -1
            macd_kdj_signals.append("MACDæ­»å‰ä¿¡å·")
        else:
            macd_kdj_signals.append("MACDéœ‡è¡")
            
        predictions['MACD_KDJ'] = {
            'score': macd_kdj_score,
            'signals': macd_kdj_signals,
            'prediction_pct': macd_kdj_score * 0.008,
            'confidence': min(abs(macd_kdj_score) * 26 + 18, 92),
            'model_type': 'technical'
        }
        
        # æ¨¡å‹5: é‡ä»·å…³ç³»æ¨¡å‹
        volume_score = 0
        volume_signals = []
        
        if latest['Volume_Ratio'] > 1.5 and latest['ROC_5'] > 2:
            volume_score = 2
            volume_signals.append("æ”¾é‡ä¸Šæ¶¨")
        elif latest['Volume_Ratio'] > 1.2 and latest['ROC_5'] > 0:
            volume_score = 1
            volume_signals.append("æ¸©å’Œæ”¾é‡ä¸Šæ¶¨")
        elif latest['Volume_Ratio'] > 1.5 and latest['ROC_5'] < -2:
            volume_score = -2
            volume_signals.append("æ”¾é‡ä¸‹è·Œ")
        elif latest['Volume_Ratio'] > 1.2 and latest['ROC_5'] < 0:
            volume_score = -1
            volume_signals.append("æ¸©å’Œæ”¾é‡ä¸‹è·Œ")
        else:
            volume_signals.append("é‡ä»·é…åˆä¸€èˆ¬")
            
        predictions['VolumePrice'] = {
            'score': volume_score,
            'signals': volume_signals,
            'prediction_pct': volume_score * 0.007,
            'confidence': min(abs(volume_score) * 22 + 8, 80),
            'model_type': 'technical'
        }
        
        return predictions
    
    # Qlibæœºå™¨å­¦ä¹ æ¨¡å‹åˆ†æ - æ··åˆç‰ˆæœ¬
    def qlib_model_analysis(data):
        """ä½¿ç”¨qlibæœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œåˆ†æ - æ”¯æŒqlibåŸç”Ÿå’Œç¬¬ä¸‰æ–¹æ¨¡å‹"""
        qlib_predictions = {}
        
        if not qlib_models:
            print("âš  æ²¡æœ‰å¯ç”¨çš„qlibæœºå™¨å­¦ä¹ æ¨¡å‹")
            return qlib_predictions
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X_df, y_series, feature_names = prepare_ml_data(data)
        
        if X_df is None or len(X_df) < 100:
            print("âš  æ•°æ®ä¸è¶³ï¼Œè·³è¿‡qlibæœºå™¨å­¦ä¹ æ¨¡å‹")
            return qlib_predictions
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œè¿™æ˜¯æœ€å…¼å®¹çš„æ ¼å¼
        X_array = X_df.values
        y_array = y_series.values
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        split_idx = int(len(X_array) * 0.8)
        X_train, X_test = X_array[:split_idx], X_array[split_idx:]
        y_train, y_test = y_array[:split_idx], y_array[split_idx:]
        
        print(f"âœ“ MLæ•°æ®å‡†å¤‡: è®­ç»ƒé›†{len(X_train)}æ ·æœ¬, æµ‹è¯•é›†{len(X_test)}æ ·æœ¬")
        
        # å¤„ç†qlibåŸç”Ÿæ¨¡å‹å’Œç¬¬ä¸‰æ–¹æ¨¡å‹
        for model_name, model_class in qlib_models.items():
            try:
                print(f"æ­£åœ¨è®­ç»ƒ{model_name}...")
                
                # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
                if model_name in ['RidgeModel', 'CatBoostModel', 'TabNetModel', 'SVMModel', 'RandomForestModel']:
                    # ç¬¬ä¸‰æ–¹æ¨¡å‹
                    try:
                        if model_name == 'RidgeModel':
                            model = model_class(alpha=1.0)
                        elif model_name == 'CatBoostModel':
                            model = model_class(iterations=100, learning_rate=0.1, depth=6, verbose=False)
                        elif model_name == 'TabNetModel':
                            # TabNetéœ€è¦ç‰¹æ®Šå¤„ç† - æ•°æ®ç»´åº¦å’Œå‚æ•°
                            model = model_class(verbose=0, seed=42, n_d=8, n_a=8, n_steps=3, gamma=1.3)
                        elif model_name == 'SVMModel':
                            model = model_class(kernel='rbf', gamma='scale', C=1.0)
                        elif model_name == 'RandomForestModel':
                            model = model_class(n_estimators=100, random_state=42, max_depth=10)
                        elif model_name == 'MLPModel':
                            # ä¼˜åŒ–MLPRegressorå‚æ•°
                            model = model_class(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42, alpha=0.001)
                        elif model_name == 'AdaBoostModel':
                            model = model_class(n_estimators=100, learning_rate=1.0, random_state=42)
                        elif model_name == 'GradientBoostingModel':
                            model = model_class(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)
                        elif model_name == 'ExtraTreesModel':
                            model = model_class(n_estimators=100, random_state=42, max_depth=12)
                        elif model_name == 'BaggingModel':
                            model = model_class(n_estimators=50, random_state=42)
                        else:
                            model = model_class()
                        
                        # ç‰¹æ®Šå¤„ç†TabNetçš„è®­ç»ƒè¿‡ç¨‹
                        if model_name == 'TabNetModel':
                            # TabNetéœ€è¦2Dç›®æ ‡å˜é‡
                            y_train_2d = y_train.reshape(-1, 1)
                            y_test_2d = y_test.reshape(-1, 1)
                            
                            model.fit(X_train, y_train_2d,
                                    eval_set=[(X_test, y_test_2d)],
                                    eval_metric=['rmse'],
                                    max_epochs=50, patience=10, batch_size=256,
                                    virtual_batch_size=128, num_workers=0,
                                    drop_last=False)
                            
                            test_pred = model.predict(X_test).flatten()
                            latest_pred = model.predict(X_array[-1:]).flatten()
                        else:
                            # æ ‡å‡†sklearnæ¥å£è®­ç»ƒ
                            model.fit(X_train, y_train)
                            test_pred = model.predict(X_test)
                            latest_pred = model.predict(X_array[-1:])
                        
                    except Exception as e:
                        print(f"âœ— {model_name}: ç¬¬ä¸‰æ–¹æ¨¡å‹å¤„ç†å¤±è´¥ - {str(e)[:100]}")
                        continue
                
                else:
                    # qlibåŸç”Ÿæ¨¡å‹ - å°è¯•sklearnåŒ…è£…å™¨æ¨¡å¼
                    try:
                        from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
                        from sklearn.linear_model import LinearRegression, Ridge
                        from sklearn.svm import SVR
                        
                        # ä½¿ç”¨sklearnæ¨¡å‹æ›¿ä»£æœ‰é—®é¢˜çš„qlibæ¨¡å‹
                        replacement_models = {
                            'LGBModel': GradientBoostingRegressor(n_estimators=100, random_state=42),
                            'LinearModel': LinearRegression(),
                            'XGBModel': GradientBoostingRegressor(n_estimators=100, random_state=42),
                            'GRU': RandomForestRegressor(n_estimators=100, random_state=42),
                            'LSTM': SVR(kernel='rbf', gamma='scale'),
                            'MLPModel': RandomForestRegressor(n_estimators=150, random_state=42),
                            'AdaBoostModel': GradientBoostingRegressor(n_estimators=80, random_state=42)
                        }
                        
                        if model_name in replacement_models:
                            model = replacement_models[model_name]
                        else:
                            model = GradientBoostingRegressor(n_estimators=100, random_state=42)
                        
                        # è®­ç»ƒæ›¿ä»£æ¨¡å‹
                        model.fit(X_train, y_train)
                        test_pred = model.predict(X_test)
                        latest_pred = model.predict(X_array[-1:])
                        
                    except Exception as e:
                        print(f"âœ— {model_name}: sklearnæ›¿ä»£æ¨¡å¼å¤±è´¥ - {str(e)[:100]}")
                        continue
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                try:
                    from sklearn.metrics import mean_squared_error, mean_absolute_error
                    
                    mse = mean_squared_error(y_test, test_pred)
                    mae = mean_absolute_error(y_test, test_pred)
                    
                    # è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§ (æ­£ç¡®é¢„æµ‹æ–¹å‘çš„æ¯”ä¾‹)
                    direction_correct = np.mean((y_test > 0) == (test_pred > 0))
                    
                    # åŸºäºæ¨¡å‹æ€§èƒ½åŠ¨æ€è®¡ç®—ç½®ä¿¡åº¦
                    base_confidence = direction_correct * 100
                    volatility_penalty = min(np.std(test_pred) * 100, 20)
                    final_confidence = max(base_confidence - volatility_penalty, 15)
                    
                    qlib_predictions[model_name] = {
                        'prediction_pct': float(latest_pred[0]),
                        'confidence': float(final_confidence),
                        'mse': float(mse),
                        'mae': float(mae),
                        'direction_accuracy': float(direction_correct),
                        'model_type': 'ml',
                        'signals': [f"MLé¢„æµ‹æ”¶ç›Š{float(latest_pred[0])*100:+.2f}%"]
                    }
                    
                    print(f"âœ“ {model_name}: æ–¹å‘å‡†ç¡®ç‡{direction_correct:.1%}, ç½®ä¿¡åº¦{final_confidence:.1f}%")
                    
                except Exception as e:
                    print(f"âœ— {model_name}: æ€§èƒ½è¯„ä¼°å¤±è´¥ - {e}")
                    
            except Exception as e:
                print(f"âœ— {model_name}: æ•´ä½“å¤„ç†å¤±è´¥ - {e}")
        
        return qlib_predictions
    
    # è®¡ç®—ç‰¹å¾
    tsla_with_features = calculate_features(tsla_data)
    
    # è¿›è¡Œå¤šæ¨¡å‹åˆ†æ
    print("\n=== å¼€å§‹å¤šç»´åº¦åˆ†æ ===")
    
    # æŠ€æœ¯åˆ†ææ¨¡å‹
    tech_predictions = multi_model_analysis(tsla_with_features.dropna())
    print(f"âœ“ æŠ€æœ¯åˆ†ææ¨¡å‹: {len(tech_predictions)}ä¸ª")
    
    # qlibæœºå™¨å­¦ä¹ æ¨¡å‹
    ml_predictions = qlib_model_analysis(tsla_with_features.dropna())
    print(f"âœ“ æœºå™¨å­¦ä¹ æ¨¡å‹: {len(ml_predictions)}ä¸ª")
    
    # åˆå¹¶æ‰€æœ‰é¢„æµ‹
    all_predictions = {**tech_predictions, **ml_predictions}
    
    # åŠ¨æ€æƒé‡åˆ†é…ç®—æ³•
    def calculate_dynamic_weights(predictions):
        """åŸºäºæ¨¡å‹æ€§èƒ½åŠ¨æ€åˆ†é…æƒé‡"""
        weights = {}
        total_weight = 0
        
        for model_name, pred_info in predictions.items():
            confidence = pred_info['confidence']
            model_type = pred_info['model_type']
            
            # åŸºç¡€æƒé‡åŸºäºç½®ä¿¡åº¦
            base_weight = confidence / 100
            
            # æ¨¡å‹ç±»å‹è°ƒæ•´
            if model_type == 'ml' and confidence > 60:
                # é«˜ç½®ä¿¡åº¦MLæ¨¡å‹æƒé‡åŠ æˆ
                type_multiplier = 1.3
            elif model_type == 'technical' and confidence > 50:
                # æŠ€æœ¯åˆ†ææ¨¡å‹ç¨³å®šæ€§åŠ æˆ
                type_multiplier = 1.1
            else:
                type_multiplier = 1.0
            
            # é¢„æµ‹å¼ºåº¦è°ƒæ•´
            pred_strength = abs(pred_info.get('prediction_pct', 0))
            strength_multiplier = 1.0 + min(pred_strength * 10, 0.5)
            
            # æœ€ç»ˆæƒé‡
            final_weight = base_weight * type_multiplier * strength_multiplier
            weights[model_name] = final_weight
            total_weight += final_weight
        
        # å½’ä¸€åŒ–æƒé‡
        if total_weight > 0:
            weights = {k: v/total_weight for k, v in weights.items()}
        
        return weights
    
    # è®¡ç®—åŠ¨æ€æƒé‡
    model_weights = calculate_dynamic_weights(all_predictions)
    
    # è®¡ç®—åŠ æƒç»¼åˆé¢„æµ‹
    weighted_prediction = sum(
        pred_info.get('prediction_pct', 0) * model_weights.get(model_name, 0)
        for model_name, pred_info in all_predictions.items()
    )
    
    # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
    weighted_confidence = sum(
        pred_info['confidence'] * model_weights.get(model_name, 0)
        for model_name, pred_info in all_predictions.items()
    )
    
    # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆè¯„åˆ†
    def calculate_technical_score(data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç»¼åˆè¯„åˆ†"""
        latest = data.iloc[-1]
        
        score = 0
        signals = []
        
        # RSIä¿¡å·
        if latest['RSI'] < 30:
            score += 2
            signals.append("RSIè¶…å–ä¿¡å·(+2)")
        elif latest['RSI'] > 70:
            score -= 2
            signals.append("RSIè¶…ä¹°ä¿¡å·(-2)")
        
        # MACDä¿¡å·
        if latest['MACD'] > latest['MACD_Signal'] and latest['MACD_Histogram'] > 0:
            score += 1
            signals.append("MACDé‡‘å‰ä¿¡å·(+1)")
        elif latest['MACD'] < latest['MACD_Signal'] and latest['MACD_Histogram'] < 0:
            score -= 1
            signals.append("MACDæ­»å‰ä¿¡å·(-1)")
        
        # å¸ƒæ—å¸¦ä¿¡å·
        if latest['Close'] < latest['BB_Lower']:
            score += 1
            signals.append("è·Œç ´å¸ƒæ—å¸¦ä¸‹è½¨(+1)")
        elif latest['Close'] > latest['BB_Upper']:
            score -= 1
            signals.append("çªç ´å¸ƒæ—å¸¦ä¸Šè½¨(-1)")
        
        # ç§»åŠ¨å¹³å‡çº¿ä¿¡å·
        if latest['Close'] > latest['MA20'] > latest['MA50']:
            score += 1
            signals.append("ä»·æ ¼ä¸Šç©¿å‡çº¿(+1)")
        elif latest['Close'] < latest['MA20'] < latest['MA50']:
            score -= 1
            signals.append("ä»·æ ¼ä¸‹ç©¿å‡çº¿(-1)")
        
        # åŠ¨é‡ä¿¡å·
        if latest['ROC_5'] > 5:
            score += 1
            signals.append("çŸ­æœŸåŠ¨é‡å¼ºåŠ²(+1)")
        elif latest['ROC_5'] < -5:
            score -= 1
            signals.append("çŸ­æœŸåŠ¨é‡ç–²å¼±(-1)")
        
        return score, signals
    
    technical_score, technical_signals = calculate_technical_score(tsla_with_features)
    
    # æœ€ç»ˆæŠ•èµ„å»ºè®®ç”Ÿæˆ
    def generate_investment_recommendation(weighted_pred, weighted_conf, tech_score):
        """ç”Ÿæˆæœ€ç»ˆæŠ•èµ„å»ºè®®"""
        
        # ç»¼åˆè¯„åˆ† (åŠ æƒé¢„æµ‹ + æŠ€æœ¯è¯„åˆ†)
        pred_score = weighted_pred * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        tech_score_norm = tech_score * 10  # å½’ä¸€åŒ–æŠ€æœ¯è¯„åˆ†
        
        # æ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´æƒé‡
        if weighted_conf >= 60:
            pred_weight, tech_weight = 0.7, 0.3
            conf_factor = 1.0
        elif weighted_conf >= 40:
            pred_weight, tech_weight = 0.6, 0.4
            conf_factor = 0.9
        elif weighted_conf >= 25:
            pred_weight, tech_weight = 0.4, 0.6
            conf_factor = 0.8
        else:
            pred_weight, tech_weight = 0.3, 0.7
            conf_factor = 0.7
        
        final_score = (pred_score * pred_weight + tech_score_norm * tech_weight) * conf_factor
        
        # ç”Ÿæˆå»ºè®®
        if weighted_conf < 20:
            recommendation = "âšª å»ºè®®è§‚æœ›"
            reason = "æ•´ä½“æ¨¡å‹ç½®ä¿¡åº¦åä½ï¼Œå¸‚åœºä¿¡å·ä¸å¤Ÿæ˜ç¡®"
            position = "ç©ºä»“è§‚æœ›"
            risk_level = "ğŸ”´ é«˜é£é™©"
        elif final_score >= 25 and weighted_conf >= 50:
            recommendation = "ğŸŸ¢ å¼ºçƒˆæ¨èä¹°å…¥"
            reason = "å¤šæ¨¡å‹é«˜ç½®ä¿¡åº¦çœ‹æ¶¨ï¼ŒæŠ€æœ¯é¢é…åˆè‰¯å¥½"
            position = "æ»¡ä»“"
            risk_level = "ğŸŸ¢ ç›¸å¯¹ä½é£é™©"
        elif final_score >= 15 and weighted_conf >= 35:
            recommendation = "ğŸŸ¡ å»ºè®®ä¹°å…¥"
            reason = "æ¨¡å‹å€¾å‘çœ‹æ¶¨ï¼Œä½†éœ€æ§åˆ¶ä»“ä½"
            position = "åŠä»“"
            risk_level = "ğŸŸ¡ ä¸­ç­‰é£é™©"
        elif final_score <= -25 and weighted_conf >= 50:
            recommendation = "ğŸ”´ å¼ºçƒˆæ¨èå–å‡º"
            reason = "å¤šæ¨¡å‹é«˜ç½®ä¿¡åº¦çœ‹è·Œï¼ŒæŠ€æœ¯é¢åå¼±"
            position = "æ¸…ä»“"
            risk_level = "ğŸ”´ é«˜é£é™©"
        elif final_score <= -15 and weighted_conf >= 35:
            recommendation = "ğŸŸ  å»ºè®®å–å‡º"
            reason = "æ¨¡å‹å€¾å‘çœ‹è·Œï¼Œå»ºè®®å‡ä»“"
            position = "è½»ä»“"
            risk_level = "ğŸŸ¡ ä¸­ç­‰é£é™©"
        else:
            recommendation = "âšª å»ºè®®è§‚æœ›"
            reason = "ä¿¡å·æ··åˆæˆ–ç½®ä¿¡åº¦ä¸è¶³ï¼Œç­‰å¾…æ›´æ˜ç¡®æ–¹å‘"
            position = "è§‚æœ›"
            risk_level = "ğŸŸ¡ ä¸­ç­‰é£é™©"
        
        return {
            'recommendation': recommendation,
            'reason': reason,
            'position': position,
            'risk_level': risk_level,
            'final_score': final_score,
            'confidence_factor': conf_factor
        }
    
    # ç”Ÿæˆæœ€ç»ˆå»ºè®®
    investment_advice = generate_investment_recommendation(
        weighted_prediction, weighted_confidence, technical_score
    )
    
    # è·å–å½“å‰æ•°æ®
    current_price = tsla_with_features['Close'].iloc[-1]
    latest_data = tsla_with_features.iloc[-1]
    
    # 2025å¹´è¡¨ç°è®¡ç®—
    if len(tsla_2025) > 0:
        year_start_price = tsla_2025['Close'].iloc[0]
        year_performance = (current_price - year_start_price) / year_start_price * 100
        year_high = tsla_2025['High'].max()
        year_low = tsla_2025['Low'].min()
    else:
        year_performance = 0
        year_high = current_price
        year_low = current_price
    
    # ç”ŸæˆmarkdownæŠ¥å‘Š (å°†æŠ•èµ„å»ºè®®æ”¾åœ¨å¼€å¤´)
    report = []
    report.append("# ğŸš— TSLAè‚¡ç¥¨æ™ºèƒ½é‡åŒ–åˆ†ææŠ¥å‘Š")
    report.append(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"**å½“å‰è‚¡ä»·**: ${current_price:.2f} ({year_performance:+.2f}% YTD)")
    report.append("")
    
    # === æœ€ç»ˆæŠ•èµ„å»ºè®®æ€»ç»“ (æ”¾åœ¨å¼€å¤´) ===
    report.append("## ğŸ’¡ æœ€ç»ˆæŠ•èµ„å»ºè®®æ€»ç»“")
    report.append("")
    report.append("### ğŸ¯ æ ¸å¿ƒå»ºè®®")
    report.append(f"- **æŠ•èµ„å»ºè®®**: {investment_advice['recommendation']}")
    report.append(f"- **å»ºè®®ä»“ä½**: {investment_advice['position']}")
    report.append(f"- **é£é™©ç­‰çº§**: {investment_advice['risk_level']}")
    report.append(f"- **å»ºè®®ç†ç”±**: {investment_advice['reason']}")
    report.append("")
    
    report.append("### ğŸ“Š å…³é”®æŒ‡æ ‡")
    report.append(f"- **åŠ æƒé¢„æœŸæ”¶ç›Š**: {weighted_prediction*100:+.2f}%")
    report.append(f"- **æ•´ä½“ç½®ä¿¡åº¦**: {weighted_confidence:.1f}%")
    report.append(f"- **ç»¼åˆè¯„åˆ†**: {investment_advice['final_score']:+.1f}%")
    report.append(f"- **æœ‰æ•ˆæ¨¡å‹æ•°é‡**: {len([p for p in all_predictions.values() if p['confidence'] >= 25])}ä¸ª")
    report.append("")
    
    report.append("### ğŸ”¥ æ ¸å¿ƒä¿¡å·")
    # å–ç½®ä¿¡åº¦æœ€é«˜çš„3ä¸ªæ¨¡å‹çš„ä¿¡å·
    top_models = sorted(all_predictions.items(), 
                       key=lambda x: x[1]['confidence'], reverse=True)[:3]
    for model_name, pred_info in top_models:
        report.append(f"- **{model_name}**: {', '.join(pred_info['signals'])}")
    report.append("")
    
    report.append("---")
    report.append("")
    
    # === è¯¦ç»†åˆ†æè¿‡ç¨‹ ===
    report.append("## ğŸ“Š åŸºç¡€æ•°æ®")
    report.append(f"- **å½“å‰è‚¡ä»·**: ${current_price:.2f}")
    report.append(f"- **2025å¹´è¡¨ç°**: {year_performance:+.2f}%")
    report.append(f"- **2025å¹´æœ€é«˜**: ${year_high:.2f}")
    report.append(f"- **2025å¹´æœ€ä½**: ${year_low:.2f}")
    report.append(f"- **å½“å‰æ³¢åŠ¨ç‡**: {latest_data['Volatility']*100:.1f}%")
    report.append("")
    
    # æŠ€æœ¯åˆ†ææ¨¡å‹è¯¦æƒ…
    report.append("## ğŸ“ˆ æŠ€æœ¯åˆ†ææ¨¡å‹")
    report.append(f"### ğŸ¯ æŠ€æœ¯è¯„åˆ†: {technical_score:+d}/10")
    
    for model_name, pred_info in tech_predictions.items():
        if pred_info['model_type'] == 'technical':
            report.append(f"#### {model_name}")
            report.append(f"- **é¢„æµ‹æ”¶ç›Š**: {pred_info['prediction_pct']*100:+.2f}%")
            report.append(f"- **ç½®ä¿¡åº¦**: {pred_info['confidence']:.1f}%")
            report.append(f"- **æƒé‡**: {model_weights.get(model_name, 0):.3f}")
            report.append(f"- **ä¿¡å·**: {', '.join(pred_info['signals'])}")
            report.append("")
    
    # qlibæœºå™¨å­¦ä¹ æ¨¡å‹è¯¦æƒ…
    if ml_predictions:
        report.append("## ğŸ¤– Qlibæœºå™¨å­¦ä¹ æ¨¡å‹")
        for model_name, pred_info in ml_predictions.items():
            report.append(f"#### {model_name}")
            report.append(f"- **é¢„æµ‹æ”¶ç›Š**: {pred_info['prediction_pct']*100:+.2f}%")
            report.append(f"- **ç½®ä¿¡åº¦**: {pred_info['confidence']:.1f}%")
            report.append(f"- **æƒé‡**: {model_weights.get(model_name, 0):.3f}")
            if 'direction_accuracy' in pred_info:
                report.append(f"- **æ–¹å‘å‡†ç¡®ç‡**: {pred_info['direction_accuracy']:.1%}")
            report.append("")
    
    # æƒé‡åˆ†é…è¯¦æƒ…
    report.append("## âš–ï¸ åŠ¨æ€æƒé‡åˆ†é…")
    report.append("### ğŸ“Š æƒé‡åˆ†é…æ˜ç»†")
    
    # æŒ‰æƒé‡æ’åº
    sorted_weights = sorted(model_weights.items(), key=lambda x: x[1], reverse=True)
    for model_name, weight in sorted_weights:
        pred_info = all_predictions[model_name]
        status = "âœ…é«˜æƒé‡" if weight >= 0.15 else "ğŸ”¸ä¸­æƒé‡" if weight >= 0.08 else "âš ï¸ä½æƒé‡"
        report.append(f"- **{model_name}**: æƒé‡{weight:.3f} "
                     f"(ç½®ä¿¡åº¦{pred_info['confidence']:.1f}%) {status}")
    
    report.append("")
    
    # æŠ€æœ¯ä¿¡å·è¯¦æƒ…
    report.append("## ğŸ“Š æŠ€æœ¯ä¿¡å·è¯¦æƒ…")
    for signal in technical_signals:
        report.append(f"- {signal}")
    report.append("")
    
    # å…³é”®æŠ€æœ¯æŒ‡æ ‡
    report.append("### ğŸ”¢ å…³é”®æŠ€æœ¯æŒ‡æ ‡")
    report.append(f"- **RSI**: {latest_data['RSI']:.1f} ({'è¶…ä¹°' if latest_data['RSI'] > 70 else 'è¶…å–' if latest_data['RSI'] < 30 else 'æ­£å¸¸'})")
    report.append(f"- **MACD**: {latest_data['MACD']:.3f}")
    report.append(f"- **KDJ-K**: {latest_data['K']:.1f}")
    report.append(f"- **5æ—¥ROC**: {latest_data['ROC_5']:.2f}%")
    report.append(f"- **20æ—¥ROC**: {latest_data['ROC_20']:.2f}%")
    report.append(f"- **å¸ƒæ—å¸¦ä½ç½®**: {latest_data['BB_Position']:.2f}")
    report.append("")
    
    # é£é™©æç¤º
    report.append("## âš ï¸ é£é™©æç¤º")
    report.append("- æœ¬åˆ†æåŸºäºå†å²æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œä»…ä¾›å‚è€ƒ")
    report.append("- è‚¡ç¥¨æŠ•èµ„æœ‰é£é™©ï¼Œè¯·æ ¹æ®ä¸ªäººæƒ…å†µè°¨æ…å†³ç­–")
    report.append("- å»ºè®®ç»“åˆåŸºæœ¬é¢åˆ†æå’Œå¸‚åœºç¯å¢ƒç»¼åˆåˆ¤æ–­")
    report.append("- åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œè®¾ç½®åˆç†çš„æ­¢æŸæ­¢ç›ˆ")
    report.append("")
    
    # æ–‡ä»¶è·¯å¾„
    report.append("## ğŸ“ ç›¸å…³æ–‡ä»¶")
    report.append(f"- **åˆ†æå›¾è¡¨**: /workspace/output/plots/tsla_comprehensive_analysis.png")
    report.append(f"- **åˆ†ææŠ¥å‘Š**: /workspace/output/tsla_analysis_report.md")
    
    # ç”Ÿæˆå›¾è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå› ä¸ºå·²ç»å¾ˆé•¿äº†ï¼‰
    print("\næ­£åœ¨ç”Ÿæˆåˆ†æå›¾è¡¨...")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # è‚¡ä»·èµ°åŠ¿
    ax1.plot(tsla_with_features.index, tsla_with_features['Close'], 'b-', linewidth=2)
    ax1.plot(tsla_with_features.index, tsla_with_features['MA20'], 'orange', alpha=0.7)
    ax1.set_title('TSLAè‚¡ä»·èµ°åŠ¿', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # RSI
    ax2.plot(tsla_with_features.index, tsla_with_features['RSI'], 'purple', linewidth=2)
    ax2.axhline(y=70, color='r', linestyle='--', alpha=0.7)
    ax2.axhline(y=30, color='g', linestyle='--', alpha=0.7)
    ax2.set_title('RSIæŒ‡æ ‡', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # MACD
    ax3.plot(tsla_with_features.index, tsla_with_features['MACD'], 'blue', linewidth=2)
    ax3.plot(tsla_with_features.index, tsla_with_features['MACD_Signal'], 'red', linewidth=2)
    ax3.set_title('MACDæŒ‡æ ‡', fontsize=12, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # æ¨¡å‹æƒé‡åˆ†å¸ƒ - å¢åŠ æ•°æ®éªŒè¯
    try:
        if sorted_weights and len(sorted_weights) > 0:
            # é™åˆ¶æ˜¾ç¤ºå‰6ä¸ªæ¨¡å‹ï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            top_weights = sorted_weights[:6]
            model_names_short = [str(name)[:10] for name, _ in top_weights]
            weights_values = [float(weight) for _, weight in top_weights]
            
            if len(model_names_short) > 0 and len(weights_values) > 0:
                ax4.bar(model_names_short, weights_values, alpha=0.7)
                ax4.set_title('æ¨¡å‹æƒé‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
                ax4.tick_params(axis='x', rotation=45)
            else:
                ax4.text(0.5, 0.5, 'æš‚æ— æœ‰æ•ˆæƒé‡æ•°æ®', ha='center', va='center', 
                        transform=ax4.transAxes, fontsize=12)
                ax4.set_title('æ¨¡å‹æƒé‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        else:
            ax4.text(0.5, 0.5, 'æš‚æ— æ¨¡å‹æƒé‡æ•°æ®', ha='center', va='center', 
                    transform=ax4.transAxes, fontsize=12)
            ax4.set_title('æ¨¡å‹æƒé‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    except Exception as e:
        print(f"âš  æƒé‡å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        ax4.text(0.5, 0.5, 'æƒé‡å›¾è¡¨ç”Ÿæˆå¤±è´¥', ha='center', va='center', 
                transform=ax4.transAxes, fontsize=12)
        ax4.set_title('æ¨¡å‹æƒé‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    chart_path = f"{plots_dir}/tsla_comprehensive_analysis.png"
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ“ åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = "\n".join(report)
    report_path = f"{output_dir}/tsla_analysis_report.md"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"âœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ¯ TSLAæ™ºèƒ½é‡åŒ–åˆ†ææ‘˜è¦")
    print("="*80)
    print(f"ğŸ“Š å½“å‰è‚¡ä»·: ${current_price:.2f} ({year_performance:+.2f}% YTD)")
    print(f"ğŸ¤– åˆ†ææ¨¡å‹: {len(all_predictions)}ä¸ª (æŠ€æœ¯{len(tech_predictions)}+ML{len(ml_predictions)})")
    print(f"ğŸ“ˆ åŠ æƒé¢„æµ‹: {weighted_prediction*100:+.2f}%")
    print(f"ğŸ¯ æ•´ä½“ç½®ä¿¡åº¦: {weighted_confidence:.1f}%")
    print(f"ğŸ’¡ æŠ•èµ„å»ºè®®: {investment_advice['recommendation']}")
    print(f"ğŸ“ å»ºè®®ä»“ä½: {investment_advice['position']}")
    print(f"âš ï¸  é£é™©ç­‰çº§: {investment_advice['risk_level']}")
    print("="*80)

except Exception as e:
    print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()

print("\nâœ… TSLAæ™ºèƒ½é‡åŒ–åˆ†æå®Œæˆï¼") 
